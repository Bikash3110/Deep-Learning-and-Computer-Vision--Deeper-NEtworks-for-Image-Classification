{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xomq192Iz0aO",
        "colab_type": "text"
      },
      "source": [
        "**Import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doyf5el8z3x7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, MaxPool2D, GlobalAveragePooling2D, Add\n",
        "from tensorflow.keras import Model\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ehkvAbOz-eO",
        "colab_type": "text"
      },
      "source": [
        "**Load DataSet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8BsJU2m0EVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load MNIST Dataset\n",
        "dataset, info = tfds.load('mnist', as_supervised = True, with_info = True)\n",
        "dataset_test, dataset_train = dataset['test'], dataset['train']\n",
        "\n",
        "#Convert\n",
        "def convert_types(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "    return image, label\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "dataset_train = dataset_train.map(convert_types).shuffle(10000).batch(batch_size)\n",
        "dataset_test = dataset_test.map(convert_types).batch(batch_size)\n",
        "#Data Augmentation\n",
        "datagen = ImageDataGenerator(rotation_range = 10, horizontal_flip = True, zoom_range = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMFpufEb0tle",
        "colab_type": "text"
      },
      "source": [
        "**ResNet50 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0o43O140xHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac7c2939-55d8-4926-d3a1-ebcaf949cd25"
      },
      "source": [
        "# Residual Block\n",
        "class ResidualBlock(Model):\n",
        "    def __init__(self, channel_in = 64, channel_out = 256):\n",
        "        super().__init__()\n",
        "      \n",
        "        channel = channel_out // 4\n",
        "        # Batch Normalization after Concolution layer\n",
        "        self.conv1 = Conv2D(channel, kernel_size = (1, 1), padding = \"same\")\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.av1 = Activation(tf.nn.relu)\n",
        "        self.conv2 = Conv2D(channel, kernel_size = (3, 3), padding = \"same\")\n",
        "        self.bn2 = BatchNormalization()\n",
        "        self.av2 = Activation(tf.nn.relu)\n",
        "        self.conv3 = Conv2D(channel_out, kernel_size = (1, 1), padding = \"same\")\n",
        "        self.bn3 = BatchNormalization()\n",
        "        self.shortcut = self._shortcut(channel_in, channel_out)\n",
        "        self.add = Add()\n",
        "        self.av3 = Activation(tf.nn.relu)\n",
        "        \n",
        "    def call(self, x):\n",
        "        h = self.conv1(x)\n",
        "        h = self.bn1(h)\n",
        "        h = self.av1(h)\n",
        "        h = self.conv2(h)\n",
        "        h = self.bn2(h)\n",
        "        h = self.av2(h)\n",
        "        h = self.conv3(h)\n",
        "        h = self.bn3(h)\n",
        "        shortcut = self.shortcut(x)\n",
        "        h = self.add([h, shortcut])\n",
        "        y = self.av3(h)\n",
        "        return y\n",
        "    \n",
        "    # Shortcut\n",
        "    def _shortcut(self, channel_in, channel_out):\n",
        "        if channel_in == channel_out:\n",
        "            return lambda x : x\n",
        "        else:\n",
        "            return self._projection(channel_out)\n",
        "        \n",
        "    def _projection(self, channel_out):\n",
        "        return Conv2D(channel_out, kernel_size = (1, 1), padding = \"same\")\n",
        "\n",
        "# ResNet           \n",
        "class ResNet50(Model):\n",
        "    def __init__(self, input_shape, output_dim):\n",
        "        super().__init__()                \n",
        "        \n",
        "        self._layers = [\n",
        "            # convolution Layer 1 (conv1)\n",
        "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\n",
        "            BatchNormalization(),\n",
        "            Activation(tf.nn.relu),\n",
        "            # convolution Layer 2 (conv2_x)\n",
        "            MaxPool2D(pool_size = (3, 3), strides = (2, 2), padding = \"same\"),\n",
        "            ResidualBlock(64, 256),\n",
        "            [\n",
        "                ResidualBlock(256, 256) for _ in range(2)                \n",
        "            ],\n",
        "            # convolution Layer 3 (conv3_x)\n",
        "            Conv2D(512, kernel_size = (1, 1), strides=(2, 2)),\n",
        "            [\n",
        "                ResidualBlock(512, 512) for _ in range(4)                \n",
        "            ],\n",
        "            # convolution Layer 4 (conv4_x)\n",
        "            Conv2D(1024, kernel_size = (1, 1), strides=(2, 2)),\n",
        "            [\n",
        "                ResidualBlock(1024, 1024) for _ in range(6)                \n",
        "            ],\n",
        "            # convolution Layer 5 (conv5_x)\n",
        "            Conv2D(2048, kernel_size = (1, 1), strides=(2, 2)),\n",
        "            [\n",
        "                ResidualBlock(2048, 2048) for _ in range(3)\n",
        "            ],\n",
        "            # Average Pooling and FC1000 layer\n",
        "            GlobalAveragePooling2D(),\n",
        "            Dense(1000, activation = tf.nn.relu),\n",
        "            Dense(output_dim, activation = tf.nn.softmax)\n",
        "        ]\n",
        "        \n",
        "    def call(self, x):\n",
        "        for layer in self._layers:\n",
        "            if isinstance(layer, list):\n",
        "                for l in layer:\n",
        "                    x = l(x)    \n",
        "            else:\n",
        "                x = layer(x)\n",
        "        return x\n",
        "       \n",
        "model = ResNet50((28, 28, 1), 10)\n",
        "model.build(input_shape = (None, 28, 28, 1))\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"res_net_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_53 (Conv2D)           multiple                  3200      \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc multiple                  256       \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   multiple                  0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "residual_block_16 (ResidualB multiple                  75904     \n",
            "_________________________________________________________________\n",
            "residual_block_17 (ResidualB multiple                  71552     \n",
            "_________________________________________________________________\n",
            "residual_block_18 (ResidualB multiple                  71552     \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           multiple                  131584    \n",
            "_________________________________________________________________\n",
            "residual_block_19 (ResidualB multiple                  282368    \n",
            "_________________________________________________________________\n",
            "residual_block_20 (ResidualB multiple                  282368    \n",
            "_________________________________________________________________\n",
            "residual_block_21 (ResidualB multiple                  282368    \n",
            "_________________________________________________________________\n",
            "residual_block_22 (ResidualB multiple                  282368    \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           multiple                  525312    \n",
            "_________________________________________________________________\n",
            "residual_block_23 (ResidualB multiple                  1121792   \n",
            "_________________________________________________________________\n",
            "residual_block_24 (ResidualB multiple                  1121792   \n",
            "_________________________________________________________________\n",
            "residual_block_25 (ResidualB multiple                  1121792   \n",
            "_________________________________________________________________\n",
            "residual_block_26 (ResidualB multiple                  1121792   \n",
            "_________________________________________________________________\n",
            "residual_block_27 (ResidualB multiple                  1121792   \n",
            "_________________________________________________________________\n",
            "residual_block_28 (ResidualB multiple                  1121792   \n",
            "_________________________________________________________________\n",
            "conv2d_96 (Conv2D)           multiple                  2099200   \n",
            "_________________________________________________________________\n",
            "residual_block_29 (ResidualB multiple                  4471808   \n",
            "_________________________________________________________________\n",
            "residual_block_30 (ResidualB multiple                  4471808   \n",
            "_________________________________________________________________\n",
            "residual_block_31 (ResidualB multiple                  4471808   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  2049000   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  10010     \n",
            "=================================================================\n",
            "Total params: 26,313,218\n",
            "Trainable params: 26,267,778\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hcc8qlm1OoS",
        "colab_type": "text"
      },
      "source": [
        "**Loss and OPtimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZDksxMI1JPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Categorial CrossEntropy\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "# Adam\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24bzsWli1Zc1",
        "colab_type": "text"
      },
      "source": [
        "**Pre-Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5XVpzlC1bgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Loss and Accuracy\n",
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
        "# Test Loss and Accuracy\n",
        "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(image, label):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(image)\n",
        "        loss = loss_object(label, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    train_loss(loss)\n",
        "    train_accuracy(label, predictions)\n",
        "        \n",
        "@tf.function\n",
        "def test_step(image, label):\n",
        "    predictions = model(image)\n",
        "    loss = loss_object(label, predictions)\n",
        "    \n",
        "    test_loss(loss)\n",
        "    test_accuracy(label, predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIgU19vl1y2j",
        "colab_type": "text"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urBKjT7f12oQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "a27d6e6a-0f8c-4e77-c50c-2b4a493bb0d9"
      },
      "source": [
        "num_epoch = 50\n",
        "start_time = time.time()\n",
        "\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epoch in range(num_epoch):    \n",
        "    for image, label in dataset_train:\n",
        "        for _image, _label in datagen.flow(image, label, batch_size = batch_size):\n",
        "            train_step(_image, _label)\n",
        "            break\n",
        "        \n",
        "    for test_image, test_label in dataset_test:\n",
        "        test_step(test_image, test_label)\n",
        "        \n",
        "    train_accuracies.append(train_accuracy.result())\n",
        "    test_accuracies.append(test_accuracy.result())    \n",
        "    \n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}, spent_time: {} min'\n",
        "    spent_time = time.time() - start_time\n",
        "    print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100, test_loss.result(), test_accuracy.result() * 100, spent_time / 60))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.6807350516319275, Accuracy: 75.73833465576172, Test Loss: 0.17914921045303345, Test Accuracy: 94.76000213623047, spent_time: 0.8261510252952575 min\n",
            "Epoch 2, Loss: 0.4209822118282318, Accuracy: 85.50833129882812, Test Loss: 0.14059126377105713, Test Accuracy: 95.79499816894531, spent_time: 1.4815698663393657 min\n",
            "Epoch 3, Loss: 0.3227335810661316, Accuracy: 89.14888763427734, Test Loss: 0.12302588671445847, Test Accuracy: 96.26000213623047, spent_time: 2.137596619129181 min\n",
            "Epoch 4, Loss: 0.26930177211761475, Accuracy: 91.08291625976562, Test Loss: 0.111155666410923, Test Accuracy: 96.63999938964844, spent_time: 2.79676558971405 min\n",
            "Epoch 5, Loss: 0.23468300700187683, Accuracy: 92.31266021728516, Test Loss: 0.1010543704032898, Test Accuracy: 96.9540023803711, spent_time: 3.4631495674451194 min\n",
            "Epoch 6, Loss: 0.21036475896835327, Accuracy: 93.18305969238281, Test Loss: 0.10000288486480713, Test Accuracy: 97.02666473388672, spent_time: 4.127037608623505 min\n",
            "Epoch 7, Loss: 0.1926209181547165, Accuracy: 93.80213928222656, Test Loss: 0.09540344774723053, Test Accuracy: 97.15714263916016, spent_time: 4.786138995488485 min\n",
            "Epoch 8, Loss: 0.17878134548664093, Accuracy: 94.28874969482422, Test Loss: 0.08982667326927185, Test Accuracy: 97.33000183105469, spent_time: 5.456946655114492 min\n",
            "Epoch 9, Loss: 0.1675993651151657, Accuracy: 94.6759262084961, Test Loss: 0.08486209064722061, Test Accuracy: 97.47000122070312, spent_time: 6.126632678508758 min\n",
            "Epoch 10, Loss: 0.15774625539779663, Accuracy: 95.00633239746094, Test Loss: 0.08467452973127365, Test Accuracy: 97.48699951171875, spent_time: 6.786258824666342 min\n",
            "Epoch 11, Loss: 0.14966240525245667, Accuracy: 95.2793960571289, Test Loss: 0.08207087963819504, Test Accuracy: 97.56182098388672, spent_time: 7.4529639403025305 min\n",
            "Epoch 12, Loss: 0.14325450360774994, Accuracy: 95.50111389160156, Test Loss: 0.08134326338768005, Test Accuracy: 97.586669921875, spent_time: 8.123345851898193 min\n",
            "Epoch 13, Loss: 0.13701054453849792, Accuracy: 95.711669921875, Test Loss: 0.07940991967916489, Test Accuracy: 97.64691925048828, spent_time: 8.785428706804911 min\n",
            "Epoch 14, Loss: 0.13178884983062744, Accuracy: 95.88594818115234, Test Loss: 0.07747215777635574, Test Accuracy: 97.71356964111328, spent_time: 9.443934206167857 min\n",
            "Epoch 15, Loss: 0.1267632246017456, Accuracy: 96.05066680908203, Test Loss: 0.07566244155168533, Test Accuracy: 97.767333984375, spent_time: 10.100914820035298 min\n",
            "Epoch 16, Loss: 0.12240956723690033, Accuracy: 96.19874572753906, Test Loss: 0.07497847080230713, Test Accuracy: 97.79438018798828, spent_time: 10.762292436758678 min\n",
            "Epoch 17, Loss: 0.1186714768409729, Accuracy: 96.32303619384766, Test Loss: 0.07348114252090454, Test Accuracy: 97.83940887451172, spent_time: 11.414149232705434 min\n",
            "Epoch 18, Loss: 0.11510583013296127, Accuracy: 96.4383316040039, Test Loss: 0.07251224666833878, Test Accuracy: 97.86833190917969, spent_time: 12.069964043299358 min\n",
            "Epoch 19, Loss: 0.11170773208141327, Accuracy: 96.5476303100586, Test Loss: 0.07133229076862335, Test Accuracy: 97.89579010009766, spent_time: 12.72330641746521 min\n",
            "Epoch 20, Loss: 0.10872664302587509, Accuracy: 96.64508056640625, Test Loss: 0.07128144055604935, Test Accuracy: 97.90850067138672, spent_time: 13.378899192810058 min\n",
            "Epoch 21, Loss: 0.10592729598283768, Accuracy: 96.73682403564453, Test Loss: 0.07006651908159256, Test Accuracy: 97.94952392578125, spent_time: 14.023181788126628 min\n",
            "Epoch 22, Loss: 0.10321252048015594, Accuracy: 96.8258285522461, Test Loss: 0.06854729354381561, Test Accuracy: 97.99500274658203, spent_time: 14.679004442691802 min\n",
            "Epoch 23, Loss: 0.10089938342571259, Accuracy: 96.90021514892578, Test Loss: 0.0675291195511818, Test Accuracy: 98.03173828125, spent_time: 15.320839989185334 min\n",
            "Epoch 24, Loss: 0.09862464666366577, Accuracy: 96.97514343261719, Test Loss: 0.06651172786951065, Test Accuracy: 98.05999755859375, spent_time: 15.975407063961029 min\n",
            "Epoch 25, Loss: 0.09660674631595612, Accuracy: 97.03966522216797, Test Loss: 0.06600925326347351, Test Accuracy: 98.07279968261719, spent_time: 16.62228946685791 min\n",
            "Epoch 26, Loss: 0.09451724588871002, Accuracy: 97.10237121582031, Test Loss: 0.06498024612665176, Test Accuracy: 98.10076904296875, spent_time: 17.285550785064697 min\n",
            "Epoch 27, Loss: 0.09274552017450333, Accuracy: 97.15926361083984, Test Loss: 0.06433403491973877, Test Accuracy: 98.12333679199219, spent_time: 17.932568303744 min\n",
            "Epoch 28, Loss: 0.0911090150475502, Accuracy: 97.2131576538086, Test Loss: 0.06320232152938843, Test Accuracy: 98.15571594238281, spent_time: 18.58114592631658 min\n",
            "Epoch 29, Loss: 0.08929196000099182, Accuracy: 97.27056884765625, Test Loss: 0.06281284987926483, Test Accuracy: 98.16827392578125, spent_time: 19.230614598592123 min\n",
            "Epoch 30, Loss: 0.08779489248991013, Accuracy: 97.31788635253906, Test Loss: 0.06220412254333496, Test Accuracy: 98.18866729736328, spent_time: 19.88672114610672 min\n",
            "Epoch 31, Loss: 0.08618320524692535, Accuracy: 97.36860656738281, Test Loss: 0.0615198127925396, Test Accuracy: 98.20935821533203, spent_time: 20.539639763037364 min\n",
            "Epoch 32, Loss: 0.0847245380282402, Accuracy: 97.41520690917969, Test Loss: 0.060963746160268784, Test Accuracy: 98.22750091552734, spent_time: 21.220547664165498 min\n",
            "Epoch 33, Loss: 0.08331730216741562, Accuracy: 97.4588394165039, Test Loss: 0.060324396938085556, Test Accuracy: 98.24757385253906, spent_time: 21.896533552805582 min\n",
            "Epoch 34, Loss: 0.08205359429121017, Accuracy: 97.50068664550781, Test Loss: 0.05961043760180473, Test Accuracy: 98.26911926269531, spent_time: 22.57302328745524 min\n",
            "Epoch 35, Loss: 0.0807461366057396, Accuracy: 97.54100036621094, Test Loss: 0.05994969606399536, Test Accuracy: 98.25971984863281, spent_time: 23.243665075302125 min\n",
            "Epoch 36, Loss: 0.07983431965112686, Accuracy: 97.57069396972656, Test Loss: 0.059338029474020004, Test Accuracy: 98.2772216796875, spent_time: 23.910540544986723 min\n",
            "Epoch 37, Loss: 0.07869051396846771, Accuracy: 97.60590362548828, Test Loss: 0.05949442461133003, Test Accuracy: 98.27081298828125, spent_time: 24.58268282810847 min\n",
            "Epoch 38, Loss: 0.0775512307882309, Accuracy: 97.64078521728516, Test Loss: 0.059051670134067535, Test Accuracy: 98.2834243774414, spent_time: 25.24148972829183 min\n",
            "Epoch 39, Loss: 0.07643555849790573, Accuracy: 97.67465209960938, Test Loss: 0.05858942121267319, Test Accuracy: 98.29410552978516, spent_time: 25.906913749376933 min\n",
            "Epoch 40, Loss: 0.07542938739061356, Accuracy: 97.7074966430664, Test Loss: 0.058032307773828506, Test Accuracy: 98.3080062866211, spent_time: 26.581792799631753 min\n",
            "Epoch 41, Loss: 0.07440666109323502, Accuracy: 97.73873901367188, Test Loss: 0.057499609887599945, Test Accuracy: 98.31853485107422, spent_time: 27.247213486830393 min\n",
            "Epoch 42, Loss: 0.0734148845076561, Accuracy: 97.77015686035156, Test Loss: 0.05691222473978996, Test Accuracy: 98.33428955078125, spent_time: 27.91935306787491 min\n",
            "Epoch 43, Loss: 0.07245820760726929, Accuracy: 97.79922485351562, Test Loss: 0.0570807084441185, Test Accuracy: 98.34139251708984, spent_time: 28.578072094917296 min\n",
            "Epoch 44, Loss: 0.07158122211694717, Accuracy: 97.82723236083984, Test Loss: 0.05669798702001572, Test Accuracy: 98.35636901855469, spent_time: 29.24653300444285 min\n",
            "Epoch 45, Loss: 0.07066944241523743, Accuracy: 97.85529327392578, Test Loss: 0.05617101117968559, Test Accuracy: 98.37244415283203, spent_time: 29.913452418645225 min\n",
            "Epoch 46, Loss: 0.06980685889720917, Accuracy: 97.88285827636719, Test Loss: 0.05580466613173485, Test Accuracy: 98.38260650634766, spent_time: 30.590836425622303 min\n",
            "Epoch 47, Loss: 0.06901270896196365, Accuracy: 97.90663146972656, Test Loss: 0.0556359700858593, Test Accuracy: 98.39127349853516, spent_time: 31.258295687039695 min\n",
            "Epoch 48, Loss: 0.06820785254240036, Accuracy: 97.93156433105469, Test Loss: 0.055259253829717636, Test Accuracy: 98.40229034423828, spent_time: 31.91333194176356 min\n",
            "Epoch 49, Loss: 0.06740095466375351, Accuracy: 97.95609283447266, Test Loss: 0.054914094507694244, Test Accuracy: 98.41510009765625, spent_time: 32.57619661887487 min\n",
            "Epoch 50, Loss: 0.0666566714644432, Accuracy: 97.97980499267578, Test Loss: 0.05460898578166962, Test Accuracy: 98.42240142822266, spent_time: 33.23585059245428 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQnH1I9J2GOr",
        "colab_type": "text"
      },
      "source": [
        "**Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ufzrsyT2Glc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6a19b9f3-7eb6-4608-ea3f-5565a2c63a69"
      },
      "source": [
        "plt.plot(train_accuracies, label = 'Train Accuracy')\n",
        "plt.plot(test_accuracies, linestyle = 'dashed', label = 'Test Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}